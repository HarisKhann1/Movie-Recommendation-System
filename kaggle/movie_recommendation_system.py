# -*- coding: utf-8 -*-
"""Movie Recommendation System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/hariskhann1/movie-recommendation-system.dad7f4ab-4b89-44b6-93db-24a50ffc74b0.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250512/auto/storage/goog4_request%26X-Goog-Date%3D20250512T190954Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dca8f3ef2547f58835d47807211bc4867123e5297601655c907373f2c1958abc5f41785df07cc6a294d6021065c609b87b56ae9b57236caf8ca7e16e20eb4e955ae5e0b72f72c97e88defa353b7d444f5a82d55e03a107154f9aeac91e738618ce65da32eea70c1e6e51558be80b9a5c37e2194d23e4690ce5261d9baf6b7cf40d3f54058c04c1656ba79e838ff8f0f812558241f1f4b46d77fd4d453147e7fdb347f55d8436fe4b62f411d5263de0c7748b11f92fac1fd713524233aea295f32dcf149aac5e1422cdd4f3f5f03ed0f1726070e7ca908ccdb760ee4a222d27c0b685ebfab425ba48ad4b128b1ca652fdb891fa3d8889f01d5b14a627f8547f75b
"""

import numpy as np
import pandas as pd
import json

movies = pd.read_csv('tmdb_5000_movies.csv')
credits = pd.read_csv('tmdb_5000_credits.csv')

movies.head(1)

credits.head(1)

# original shape of the movies data
movies.shape

# original shape of the credits data
credits.shape

# merging the data both dataset into movies on the basis of title
movies = movies.merge(credits, on='title')

# movies shape changed to 23 from 20
movies.shape

movies.head(1)

# title
# genres
# id
# keywords
# overview
# cast
# crew

movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]
movies.info()

movies.head(1)

# checking for the null values in new dataset
movies.isnull().sum()

# since the overview has three null values so we can remove them as the number is ot so big
movies.dropna(inplace=True)

movies.isnull().sum()

# checking for the duplicates
movies.duplicated().sum()

movies['genres'][0]

# '[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]'
# need transformation in this form to create tags
# ['Action', 'Adventure', 'Fantasy', 'Science Fiction']
def convert(obj):
    lst = [i['name'] for i in json.loads(obj)] # converting the list of string into python list
    return lst

movies['genres'] = movies['genres'].apply(convert)

# genres colums tranform in the list form
movies.head(1)

# now for keywords
movies['keywords'] = movies['keywords'].apply(convert)

movies.head(1)

# now get the names of the top three actors/actress
def convert_top_three(obj):
    counter = 0
    lst = []
    data = json.loads(obj)
    for i in data:
        if counter != 3:
            lst.append(i['name'])
            counter += 1
        else:
            break
    return lst

movies['cast'] = movies['cast'].apply(convert_top_three)

movies.head(1)

# now we only need the name of the director of the movie
def find_director(obj):
    lst = []
    data = json.loads(obj)
    for i in data:
        if i['job'] == 'Director':
            lst.append(i['name'])
            break
    return lst

movies['crew'] = movies['crew'].apply(find_director)

movies.head()

# in the overview column we have a list and we need to convert it to list
movies['overview'] = movies['overview'].apply(lambda x:x.split())

movies.head(1)

# now will remove the spaces between the names or words like Haris Khan should
# HarisKhan so that the model donot get Confuse with Haris Imtiaz
# Transformation Haris Khan into HarisKhan and Haris Imtiaz into HarisImtiaz

movies['genres'] = movies['genres'].apply(lambda x:[i.replace(" ", "") for i in x])
movies['keywords'] = movies['keywords'].apply(lambda x:[i.replace(" ", "") for i in x])
movies['cast'] = movies['cast'].apply(lambda x:[i.replace(" ", "") for i in x])
movies['crew'] = movies['crew'].apply(lambda x:[i.replace(" ", "") for i in x])

# now the space is removed from all the columns
movies.head(1)

# now will create a new column name "tags" from overview, genres, keywords, cast and crew
# as the recommandation is system is based on the tags (content base)

movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

# tags column created
movies.head(1)

# now we donnot need the overview, genres, keywords,cast and crew column
# creating new data frame

new_df = movies[['movie_id', 'title', 'tags']]

new_df.head()

# now convert the list of tags into a string

new_df['tags'] = new_df['tags'].apply(lambda x:" ".join(x))

# we got the string
new_df.head(1)

new_df['tags'][0]

# now to covert all the words into lower case
new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())

# preprocessing done
new_df['tags'][0]

"""
    now there is words that need to be in its base form like tere is words
    like action, actions which is same
    loved, loving, love ---> love, love, love
"""
import nltk

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

# helper function to convert words to its base form
def stem(text):
    y = []
    for i in text.split():
        # print(i)
        y.append(ps.stem(i))
    return " ".join(y)

# stem('in the 22nd century, a paraplegic marine is dispatched to the moon pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization. action adventure fantasy sciencefiction cultureclash future spacewar spacecolony society spacetravel futuristic romance space alien tribe alienplanet cgi marine soldier battle loveaffair antiwar powerrelations mindandsoul 3d samworthington zoesaldana sigourneyweaver jamescameron')

new_df['tags'] = new_df['tags'].apply(stem)

# creating vectors for each movie
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000, stop_words='english')

# 4806 movies (row) and 5000 words (col)
cv.fit_transform(new_df['tags']).toarray().shape

vectors = cv.fit_transform(new_df['tags']).toarray()

# each movies transform into vectors
vectors

# for i in cv.get_feature_names_out():
#     print(i)

# now since the created the vectors now its to calculate the distance between each vectore
# we are calculating the angle between the vectors since we are dealing with high dimentional array
# cosine teetha (cosine_similarity() in sklaran)

from sklearn.metrics.pairwise import cosine_similarity

# just pass all the vectors to cosine_similarity and that will gives as the the distance between each of the vectors
count = 1
# cosine_similarity(vectors) #all vectors
# cosine_similarity(vectors).shape #shape

similarity = cosine_similarity(vectors)

# each row has the similarity with all the vectors (movies) as seem the first element means first has 100% similary with
# the first movie, which is the same movie if print the second movie the second index will be 1 indicates 100% similarity
# for i in similarity[0]:
# diagnol of the similary will be one
#     print(i)
similarity[0]

# the function return the most five similar movie to given movie

def recommand(movie):
    movie_index = new_df[new_df['title'] == movie].index[0] # index of the given movie
    distances = similarity[movie_index] # get all the movies that is similar to the given movie (distances)
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x:x[1])[1:6] # get the most five similar movies

    for i in movies_list:
        print(new_df.iloc[i[0]].title) #title of of movie with respect to index of the movies
        print(i[0]) # print the index of the similar movie

recommand('From Russia with Love')

import pickle

pickle.dump(similarity, open('similarity.pkl', 'wb'))